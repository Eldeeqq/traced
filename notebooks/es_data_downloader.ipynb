{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8604bf0f-855f-448f-9308-12b6d6fa74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser will not be automatically opened.\n",
      "Please visit the following URL:\n",
      "\n",
      "https://device.sso.eu-north-1.amazonaws.com/\n",
      "\n",
      "Then enter the code:\n",
      "\n",
      "RZJC-TVQK\n",
      "\n",
      "Alternatively, you may visit the following URL which will autofill the code upon loading:\n",
      "https://device.sso.eu-north-1.amazonaws.com/?user_code=RZJC-TVQK\n",
      "Successfully logged into Start URL: https://diplomka.awsapps.com/start\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "export AWS_DEFAULT_PROFILE=diplomka && /home/perinja/aws/aws sso login --no-browser --profile AdministratorAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887e6643-3015-4f0f-8354-f5a16f2d56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import time\n",
    "import tempfile\n",
    "import secrets\n",
    "import random\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import os\n",
    "import multiprocessing\n",
    "import json\n",
    "import json\n",
    "import json\n",
    "import glob \n",
    "import boto3\n",
    "import logging\n",
    "import logging.handlers\n",
    "from typing import Iterator, Optional\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from elasticsearch.helpers import scan\n",
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d725fd43-b90d-40aa-a4df-ade27642d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(profile_name='AdministratorAccess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8ae016e-1cd2-447e-ae91-7f144a321890",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket('wmdwalm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc6a161-a413-4ab6-88be-4043df9fbcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 4, 18, 10, 35, 15, tzinfo=tzlocal())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bucket.creation_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9adc7920-3e78-4920-a1f0-5e46d209230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to ES.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts=[{'host': 'atlas-kibana.mwt2.org', 'port':9200, 'scheme':'https'}],\n",
    "    basic_auth=('perinja', getpass())\n",
    ")\n",
    "    \n",
    "es.options(request_timeout=60)\n",
    "\n",
    "if es.ping():\n",
    "    print('connected to ES.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee776ff-81ea-401f-8436-b0ec36a5ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 1672531201000\n",
    "END = 1680307201000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "752d4e5e-3044-498b-a5b3-7a24fd4fada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sand-ci/AlarmsAndAlerts\n",
    "\n",
    "def query_ps_trace(dt) -> Optional[Iterator[dict]]:\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\"must\": [\n",
    "                {\"range\": {\"timestamp\": {\"gt\": dt[0], \"lte\": dt[1]}}}\n",
    "            ]}\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        return scan_gen(\n",
    "            scan(\n",
    "                es,\n",
    "                index=\"ps_trace\",\n",
    "                query=query,\n",
    "                filter_path=[\"_scroll_id\", \"_shards\", \"hits.hits._source\"],\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "def query_trace_change(dt) -> Optional[Iterator[dict]]:\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"term\": {\"event\": \"path changed\"}},\n",
    "                    {\"range\": {\"created_at\": {\"gt\": dt[0], \"lte\": dt[1]}}},\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        return scan_gen(\n",
    "            scan(\n",
    "                es,\n",
    "                index=\"aaas_alarms\",\n",
    "                query=query,\n",
    "                filter_path=[\"_scroll_id\", \"_shards\", \"hits.hits._source\"],\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def query_specific_site(src_site, dest_site, start, end) -> Optional[Iterator[dict]]:\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\"must\": [\n",
    "                        {\"range\": {\"timestamp\": {\"gt\": start, \"lte\": end}}},\n",
    "                        {\"term\": {\"dest_site\": dest_site}},\n",
    "                        {\"term\": {\"src_site\": src_site}},\n",
    "            ]\n",
    "                    }\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        return scan_gen(\n",
    "            scan(\n",
    "                es,\n",
    "                index=\"ps_trace\",\n",
    "                query=query,\n",
    "                filter_path=[\"_scroll_id\", \"_shards\", \"hits.hits._source\"],\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "def scan_gen(scan) -> Iterator[dict]:\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(scan)[\"_source\"]\n",
    "        except Exception:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78809ab-e961-4a05-bb71-dd57141921f4",
   "metadata": {},
   "source": [
    "## Traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9a6e888-05dc-47f2-bd02-6c6c4784be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"batcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af89b87b-f0e6-4dd7-812e-0de90e9d42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb2058f-c262-4d9d-ad9c-c5cdae73c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = logging.handlers.RotatingFileHandler(\"log.txt\", maxBytes=(1048576*5), backupCount=7)\n",
    "fmt = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "fh.setFormatter(fmt)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25da21d3-d61a-4956-8995-435550ced5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_site_to_s3(src_site, dest_site, start, end):\n",
    "    data: Optional[Iterator[dict]] = query_specific_site(src_site=src_site, dest_site=dest_site, start=start, end=end)\n",
    "    iterate = True\n",
    "\n",
    "    if data is None:\n",
    "        print(\"No data\")\n",
    "        return\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix='.zip') as file:\n",
    "        logger.info(\"Downloading into %s\", file.name)\n",
    "        with tqdm() as files:\n",
    "            with zipfile.ZipFile(file.name, mode=\"w\", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zip_file: \n",
    "                while iterate:\n",
    "                    try:\n",
    "                        item = next(data)\n",
    "                        ts = item[\"timestamp\"]\n",
    "                        file_name = datetime.fromtimestamp(ts/1000).isoformat() + f'-{secrets.token_hex(nbytes=6)}.json'\n",
    "                        zip_file.writestr(file_name, json.dumps(item))\n",
    "                        files.update()\n",
    "                    except StopIteration as e:\n",
    "                        logger.info(\"Testing %s\", file.name)\n",
    "                        zip_file.testzip()\n",
    "                        zip_file.close()\n",
    "                        iterate = False\n",
    "\n",
    "            logger.info(\"Uploading %s\", file.name)\n",
    "            my_bucket.upload_file(file.name, f\"sites/{src_site}-{dest_site}.zip\")\n",
    "            logger.info(\"OK %s\", file.name)\n",
    "    logger.info(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da294caa-e929-4d5f-9d9a-b06efba35c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44635it [00:15, 2871.38it/s]\n"
     ]
    }
   ],
   "source": [
    "download_site_to_s3(src_site=\"CA-SFU-T2\",dest_site=\"CSCS-LCG2\", start=START, end=END)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
